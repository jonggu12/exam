{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어간추출(stemming)\n",
    "* 어간(stem) : 변하지 않는 단어의 핵심 \n",
    "    * 예시: \"running\", \"runs\", \"ran\" 등의 단어는 어간 추출을 통해 기본 형태인 \"run\"으로 변환될 수 있습니다.\n",
    "    \n",
    "* 접사(Affix) : 어간에 붙여서 새로운 단어를 만드는 부분, 접두사(prefix) + 접미사(suffix)\n",
    "    * unhappy의 un접두사, -ing 접미사\n",
    "    \n",
    "    \n",
    "* 어간추출 : 단어의 어간만 남기고 다른 접사 등을 제거해서 단어를 축약하는 과정\n",
    "* 주먹구구식으로 단어를 만듬, 사전에 존재하지 않을 수 있음\n",
    "* ex) running, runs, ran의 어간은 run\n",
    "* 단순하고 규칙적인 변환을 수행하여 빠르게 처리가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* PorterStemmer\n",
    "    * Martin Porter가 개발한 알고리즘\n",
    "    * 규칙 기반의 접근 방식을 사용하여 단어를 변환함\n",
    "    * 단어의 어미를 제거하고 어간을 찾아내어 축약하는 방식으로 작동\n",
    "    * 자주 사용되는 형태를 유지(보수적인 접근)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 단어:running, 어간 추출 결과: run\n",
      "원본 단어:files, 어간 추출 결과: file\n",
      "원본 단어:cats, 어간 추출 결과: cat\n",
      "원본 단어:trouble, 어간 추출 결과: troubl\n",
      "원본 단어:running, 어간 추출 결과: run\n",
      "원본 단어:friendships, 어간 추출 결과: friendship\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# PorterStemmer 객체 생성\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# 어간 추출할 단어들 \n",
    "words = ['running','files','cats','trouble','running','friendships']\n",
    "\n",
    "# 단어들의 어간 추출\n",
    "for word in words:\n",
    "    stemmed_word = porter.stem(word)\n",
    "    print(f\"원본 단어:{word}, 어간 추출 결과: {stemmed_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* LancasterStemmer\n",
    "    * Chris D. Paice가 개발한 알고리즘\n",
    "    * PorterStemmer보다 더 적극적인 방식으로 단어를 축약\n",
    "    * 많은 규칙을 적용하여 단어를 더 짧게 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 단어:running, 어간 추출 결과: run\n",
      "원본 단어:files, 어간 추출 결과: fil\n",
      "원본 단어:cats, 어간 추출 결과: cat\n",
      "원본 단어:trouble, 어간 추출 결과: troubl\n",
      "원본 단어:running, 어간 추출 결과: run\n",
      "원본 단어:friendships, 어간 추출 결과: friend\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# LancaterStemmer 객체 생성\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "# 어간 추출할 단어들 \n",
    "words = ['running','files','cats','trouble','running','friendships']\n",
    "\n",
    "# 단어들의 어간 추출\n",
    "for word in words:\n",
    "    stemmed_word = lancaster.stem(word)\n",
    "    print(f\"원본 단어:{word}, 어간 추출 결과: {stemmed_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     \n",
    "\n",
    "* 포터 알고리즘 규칙\n",
    "    ALIZE = AL\n",
    "    ANCE -> 제거\n",
    "    ICAL -> IC\n",
    "\n",
    "    formalize -> formal\n",
    "    allowance -> allow\n",
    "    electricical -> electric\n",
    "\n",
    "* 랭체스터 알고리즘 규칙\n",
    "    단어의 끝에 있는 접미사를 제거('-ing','-ed' 제거)\n",
    "    복잡한 규칙에 따라 단어를 축약('e'로 끝나는 단어는 e를 제거, 'ational' 이라는 접미사를 'ate'로 변경)\n",
    "   \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter stemmer로 어간 추출 후 : ['polici', 'do', 'organ', 'have', 'go', 'love', 'live']\n",
      "Lancaster Stemmer로 어간 추출 후 : ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "words = ['policy','doing','organization','have','going','love', 'lives']\n",
    "\n",
    "\n",
    "porter_result = [porter_stemmer.stem(w) for w in words]\n",
    "lancaster_result = [lancaster_stemmer.stem(w) for w in words]\n",
    "\n",
    "print('Porter stemmer로 어간 추출 후 :',porter_result)\n",
    "print(\"Lancaster Stemmer로 어간 추출 후 :\",lancaster_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 표제어 추출 (Lemmatization) : 단어의 원형을 찾고 단어의 형태소적 문법적 특성을 고려하여 사전에 등재된단어로 변환\n",
    "\n",
    "\n",
    "* 어간추출보다 정확함\n",
    "* ex) 'am','are','is'의 표제어는 'be'\n",
    "* 문법적, 의미적인 측면을 고려하므로 복잡하고 정확한 처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/choejong-\n",
      "[nltk_data]     gyu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본단어: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "Lemmatization 결과: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy','doing','organization','have','going','love', 'lives','fly','dies','watched','has','starting']\n",
    "\n",
    "lemmatizer_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print('원본단어:',words)\n",
    "print('Lemmatization 결과:',lemmatizer_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('dies', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('watched', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has', 'v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
