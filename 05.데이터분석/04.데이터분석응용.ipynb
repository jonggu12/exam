{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11월 20일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. 데이터 사전처리 : Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_1. 누락 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns #seaborn : matplotlib을 기반으로 만들어진 고수준 인터페이스, matplotlib의 상위계층\n",
    "df = sns.load_dataset('titanic') # seaborn 내에 있는 내장 함수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 누락 데이터 존재 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deck\n",
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# .value_counts()\n",
    "\n",
    "nan_deck = df['deck'].value_counts(dropna=False)  #dropna = True/False : NaN 값 미포함/포함\n",
    "print(nan_deck)                                   #dropna가 false 일경우 nan값 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n"
     ]
    }
   ],
   "source": [
    "# .isnull() -> True=NaN, False = NaN 아님, 셀이 NaN이면 해당 위치에 True가 표시되고, NaN이 아니면 False가 표시\n",
    "print(df.head().isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# .notnull() -> True = NaN 아님, False = NaN, isnull과 반대인 경우\n",
    "\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 누락 데이터 개수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "survived       5\n",
      "pclass         5\n",
      "sex            5\n",
      "age            5\n",
      "sibsp          5\n",
      "parch          5\n",
      "fare           5\n",
      "embarked       5\n",
      "class          5\n",
      "who            5\n",
      "adult_male     5\n",
      "deck           2\n",
      "embark_town    5\n",
      "alive          5\n",
      "alone          5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head().isnull().sum(axis=0))   # -> NaN 값 개수를 sum\n",
    "print(df.head().notnull().sum(axis=0))  # -> NaN이 아닌 값 개수를 sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 누락 데이터 제거 : .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 열 단위 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "missing_df = df.isnull() # isnull -> null 값이 있을 경우 True 없으면 false\n",
    "\n",
    "missing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived : 0\n",
      "pclass : 0\n",
      "sex : 0\n",
      "age : 177\n",
      "sibsp : 0\n",
      "parch : 0\n",
      "fare : 0\n",
      "embarked : 2\n",
      "class : 0\n",
      "who : 0\n",
      "adult_male : 0\n",
      "deck : 688\n",
      "embark_town : 2\n",
      "alive : 0\n",
      "alone : 0\n"
     ]
    }
   ],
   "source": [
    "# 정확히 어떤 열에 NaN 값이 몇 개 있는지\n",
    "\n",
    "for col in missing_df.columns: # 데이터 프레임의 각 열에 대해 반복\n",
    "    missing_count = missing_df[col].value_counts() \n",
    "    \n",
    "    try:\n",
    "        print(col,\":\", missing_count[True])  #missing_count(=NaN 값의 수)가 존재하면 개수 출력\n",
    "    except:\n",
    "        print(col,\":\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
      "       'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 특정 조건을 만족하는 열을 모두 삭제\n",
    "# axis= 0 : 행, axis = 1 : 열\n",
    "df_thresh = df.dropna(axis=1,thresh=500)  # NaN 값이 500개 이상(thresh), 열 단위(axis=1로 삭제(.dropna())\n",
    "print(df_thresh.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행 단위 제거 : 속성 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "885         0       3  female  39.0      0      5  29.1250        Q   Third   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "885  woman       False  NaN   Queenstown    no  False  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[714 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 속성 subset 활용 : 특정 열에서 데이터가 없는 모든 행 삭제\n",
    "# how = 'any' : 하나라도 NaN 값을 포함하면 해당 행을 삭제\n",
    "df_age = df.dropna(subset=['age'],how='any',axis=0)  # subset = NaN 값을 찾을 열, how = 삭제 기준, any는 하나라도 있으면, axis=0은 열 단위가 아닌 행 단위로 찾겠다는 뜻\n",
    "print(len(df_age))\n",
    "df_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex  age  sibsp  parch     fare embarked   class  \\\n",
       "5           0       3    male  NaN      0      0   8.4583        Q   Third   \n",
       "17          1       2    male  NaN      0      0  13.0000        S  Second   \n",
       "19          1       3  female  NaN      0      0   7.2250        C   Third   \n",
       "26          0       3    male  NaN      0      0   7.2250        C   Third   \n",
       "28          1       3  female  NaN      0      0   7.8792        Q   Third   \n",
       "..        ...     ...     ...  ...    ...    ...      ...      ...     ...   \n",
       "859         0       3    male  NaN      0      0   7.2292        C   Third   \n",
       "863         0       3  female  NaN      8      2  69.5500        S   Third   \n",
       "868         0       3    male  NaN      0      0   9.5000        S   Third   \n",
       "878         0       3    male  NaN      0      0   7.8958        S   Third   \n",
       "888         0       3  female  NaN      1      2  23.4500        S   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "5      man        True  NaN   Queenstown    no   True  \n",
       "17     man        True  NaN  Southampton   yes   True  \n",
       "19   woman       False  NaN    Cherbourg   yes   True  \n",
       "26     man        True  NaN    Cherbourg    no   True  \n",
       "28   woman       False  NaN   Queenstown   yes   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "859    man        True  NaN    Cherbourg    no   True  \n",
       "863  woman       False  NaN  Southampton    no  False  \n",
       "868    man        True  NaN  Southampton    no   True  \n",
       "878    man        True  NaN  Southampton    no   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "\n",
       "[177 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 DataFrame에서 'age' 열에 NaN 값을 가진 행 찾기\n",
    "missing_age_rows = df[df['age'].isnull()]\n",
    "missing_age_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   age   income\n",
       "0  Alice  25.0  50000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# how를 all 로 설정하게되면 age가 nan값 일 경우 그 행 모두 삭제\n",
    "data = {'name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'age': [25, np.nan, np.nan],\n",
    "        'income': [50000, 60000, np.nan]}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=['age'], how='all', axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 누락 데이터 치환 : .fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 숫자형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['age'].head(10))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 특정 열의 NaN 값을 다른 데이터의 평균으로 변경하기 1. 평균 mean\n",
    "mean_age = df['age'].mean(axis=0)        # NaN 값 제외\n",
    "df['age'].fillna(mean_age,inplace=True)\n",
    "\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5    28.0\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 특정 열의 NaN 값을 다른 데이터의 평균으로 변경하기 2. 중앙값 median\n",
    "import seaborn as sns\n",
    "df2 = sns.load_dataset('titanic')\n",
    "\n",
    "print(df2['age'].head(10))\n",
    "print('\\n')\n",
    "\n",
    "median_age = df2['age'].median(axis=0)        # NaN 값 제외\n",
    "df2['age'].fillna(median_age,inplace=True)\n",
    "\n",
    "print(df2['age'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최빈값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embark_town\n",
      "Southampton    644\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 승선 도시별 데이터 수 확인하기\n",
    "\n",
    "most_freq = df['embark_town'].value_counts(dropna=True)  \n",
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southampton\n"
     ]
    }
   ],
   "source": [
    "# 승선도시별 데이터 수가 가장 많은 곳 확인하기 # idxmax = 최빈값 -> value_counts중에서 nan값 제외하고 최빈값찾는것\n",
    "# 최빈값 : 가장 자주 나온 숫자 (빈도가 가장 높은 숫자)\n",
    "\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()  \n",
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 채워넣기\n",
    "\n",
    "df['embark_town'].fillna(most_freq,inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인접값 : 속성 method='ffill / bfill'을 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# method = 'ffill' (forward fill) : 이전 값으로 채우기\n",
    "\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(method='ffill',inplace=True) #'ffill'은 forward fill의 약자로, NaN 값을 이전 행의 값으로 채우는 방법                                                      #즉, NaN 값이 나타나면 바로 직전 행의 값으로 해당 NaN을 채웁니다.\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "830      Cherbourg\n",
      "831    Southampton\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829      Cherbourg\n",
      "830      Cherbourg\n",
      "831    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# method = bfill (backward fill) 다음값으로 채우기\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'][825:832])\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(method='bfill',inplace=True)\n",
    "print(df['embark_town'][825:832])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_2. 중복 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 존재 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1':['a','a','b','a','b'],'c2':[1,1,1,2,2],'c3':[1,1,2,2,2]})\n",
    "\n",
    "print(df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# .duplicated() : 각 행이 이전에 나타난 행과 동일한지 여부를 판단\n",
    "\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 특정 칼럼 안에서 중복값 찾기\n",
    "\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n"
     ]
    }
   ],
   "source": [
    "# 중복행 제거\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "# 특정 열을 기준으로 중복 행 제거\n",
    "df3 = df.drop_duplicates(subset=['c2','c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_3. 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단위 변환 \n",
    ": 같은 데이터 셋에서 서로 다른 측정 단위에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/choejong-gyu/Documents/05.데이터분석/data1/auto-mpg.csv',header=None)\n",
    "\n",
    "# 칼럼 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "print(df.head(3))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name   kpl  \n",
      "0       1  chevrolet chevelle malibu  7.65  \n",
      "1       1          buick skylark 320  6.38  \n",
      "2       1         plymouth satellite  7.65  \n"
     ]
    }
   ],
   "source": [
    "# mpg(mile per gallon) : 영미, kpl(killometer per liter) : 한국\n",
    "# 1 mile = 1.60934km\n",
    "# 1 gallon = 3.78541L\n",
    "\n",
    "mpg_to_kpl = 1.60934 / 3.78541 # =0.425 kpl\n",
    "\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "df['kpl'] = df['kpl'].round(2) # 소수점 둘째 자리까지 반올림\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자료형 변환\n",
    ": .astype('자료형 명칭') -> '자료형 명칭'자료형으로 변함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자형으로 된 숫자 -> 숫자형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower       object\n",
      "weight          float64\n",
      "acceleration    float64\n",
      "model year        int64\n",
      "origin            int64\n",
      "name             object\n",
      "kpl             float64\n",
      "dtype: object\n",
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['horsepower'].unique()) # horsepower에서 고유한 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# horsepower 열에 누락 데이터 '?' 우선 삭제\n",
    "import numpy as np\n",
    "\n",
    "df['horsepower'].replace('?',np.nan,inplace=True) # horsepower열에서 '?'를 nan으로 바꿈\n",
    "df.dropna(subset=['horsepower'],axis=0,inplace=True) # dropna를 할때 subset은 nan값을 제거할때 어느 열을 기준할지 정함,행을 기준으로 작업 수행\n",
    "df['horsepower'] = df['horsepower'].astype('float')     # .astype('자료형 명칭') , horsetype열에 astype를 float형으로 변환하는 작업\n",
    "\n",
    "print(df['horsepower'].dtypes) # horsepower의 타입이 뭔지 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130. 165. 150. 140. 198. 220. 215. 225. 190. 170. 160.  95.  97.  85.\n",
      "  88.  46.  87.  90. 113. 200. 210. 193. 100. 105. 175. 153. 180. 110.\n",
      "  72.  86.  70.  76.  65.  69.  60.  80.  54. 208. 155. 112.  92. 145.\n",
      " 137. 158. 167.  94. 107. 230.  49.  75.  91. 122.  67.  83.  78.  52.\n",
      "  61.  93. 148. 129.  96.  71.  98. 115.  53.  81.  79. 120. 152. 102.\n",
      " 108.  68.  58. 149.  89.  63.  48.  66. 139. 103. 125. 133. 138. 135.\n",
      " 142.  77.  62. 132.  84.  64.  74. 116.  82.]\n"
     ]
    }
   ],
   "source": [
    "print(df['horsepower'].unique()) # ?가 사라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 카테고리형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(df['origin'].unique()) # 자동차의 제조 국가 또는 출시국가를 나타내는 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'JAPAN' 'EU']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df['origin'].replace({1:'USA',2:'EU', 3:'JAPAN'},inplace=True)\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes) # object는 문자열 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n"
     ]
    }
   ],
   "source": [
    "df['origin'] = df['origin'].astype('category') # 타입을 category로 변환\n",
    "print(df['origin'].dtypes) # category는 범주형 데이터 ex) 남자, 여자 -> 범주형 데이터\n",
    "                            #여기서 origin은 USA,EU,JAPAN이 범주형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232    77\n",
      "367    82\n",
      "241    77\n",
      "Name: model year, dtype: int64\n",
      "153    75\n",
      "193    76\n",
      "14     70\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "print(df['model year'].sample(3))       # .sample(n) : 임의의 행을 n개 반환\n",
    "df['model year'] = df['model year'].astype('category')   # 모델 연도 -> 범주형 데이터로 변환\n",
    "print(df['model year'].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_4. 범주형(카테고리) 데이터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구간 분할 binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "\n",
      "\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/choejong-gyu/Documents/05.데이터분석/data1/auto-mpg.csv',header=None)\n",
    "\n",
    "# 칼럼 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열에 누락 데이터 '?' 우선 삭제\n",
    "import numpy as np\n",
    "\n",
    "df['horsepower'].replace('?',np.nan,inplace=True)\n",
    "df.dropna(subset=['horsepower'],axis=0,inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')     # .astype('자료형 명칭')\n",
    "\n",
    "print(df['horsepower'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구간 분할을 위한 경계선 설정값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 103  32] [ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    }
   ],
   "source": [
    "# count : 구간에 속하는 데이터의 수\n",
    "# bin_dividers : 구간을 나누는 경곗값\n",
    "# 경계선을 나눌 값들만 찾아낸 거임\n",
    "\n",
    "count, bin_dividers = np.histogram(df['horsepower'],bins=3)     # bins=n : 구간 개수 n, n등분 ex) bins=3 은 3개의 구간\n",
    "print(count,bin_dividers) # 46~107의 구간에서는 257개 데이터가 있고\n",
    "                          # 107.3 ~ 168의 구간에서는 103개의 데이터가 있고\n",
    "                          # 168~230 의 구간에서는 32의 데이터가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .cut() : 실제로 분할\n",
    "속성 x = , bins = , labels = , include_lowest="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     horsepower hp_bin\n",
      "383        67.0    저출력\n",
      "174        97.0    저출력\n",
      "219        96.0    저출력\n",
      "89        150.0   보통출력\n",
      "125        95.0    저출력\n",
      "68        155.0   보통출력\n",
      "66        150.0   보통출력\n",
      "270        95.0    저출력\n",
      "214       130.0   보통출력\n",
      "189       120.0   보통출력\n",
      "215       150.0   보통출력\n",
      "311        70.0    저출력\n",
      "50         90.0    저출력\n",
      "348        62.0    저출력\n",
      "251       139.0   보통출력\n"
     ]
    }
   ],
   "source": [
    "# .cut() : 실제로 분할해서 변수에 저장\n",
    "bin_names=['저출력','보통출력','고출력']\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],       # 데이터 배열\n",
    "                      bins=bin_dividers,        # 경계 값 리스트\n",
    "                      labels = bin_names,       # bin 이름\n",
    "                      include_lowest=True)      # 첫 경계값 포함(True), False로 지정하면 왼쪽 경계값 포함 x\n",
    "                                                # \n",
    "\n",
    "print(df[['horsepower','hp_bin']].sample(15))   # 분할되어서 카테고리로 나누어졌는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     보통출력\n",
       "1     보통출력\n",
       "2     보통출력\n",
       "3     보통출력\n",
       "4     보통출력\n",
       "5      고출력\n",
       "6      고출력\n",
       "7      고출력\n",
       "8      고출력\n",
       "9      고출력\n",
       "10     고출력\n",
       "11    보통출력\n",
       "12    보통출력\n",
       "13     고출력\n",
       "14     저출력\n",
       "Name: hp_bin, dtype: category\n",
       "Categories (3, object): ['저출력' < '보통출력' < '고출력']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hp_bin'].head(15) #Categories (3, object): ['저출력' < '보통출력' < '고출력']일때 고출력0,보통1,저출력2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 데이터 인코딩의 종류\n",
    "1. 레이블 인코딩 label encoding\n",
    ": 카테고리 항목을 뽑아 숫자로 라벨링\n",
    "-> 문제점: 숫자 가중치가 생김 \n",
    "\n",
    "2. 원핫인코딩 One-Hot encoding\n",
    ": 카테고리 항목을 뽑아 2차원 데이터(희소행렬)로 만들어 포지션 표시\n",
    "-> 저장공간 낭비 문제를 해결하기 위해 인베이딩 압축이라는 게 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#전처리를 위한 encounter 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder() # 범주형 데이터를 바이너리 형태로 변환 -> 머신러닝모델에 적용하는 방법\n",
    "\n",
    "#label encoder로 카테고리형 데이터를 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15)) # 저출력 보통출력 고출력을 매핑한거\n",
    "print(onehot_labeled)                                               # 저출력 2,보통출력1,고출력0\n",
    "print(type(onehot_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# OneHotEncoder 의 예제 범주형 데이터를 바이너리 형태로 변환 -> 머신러닝모델에 적용하는 방법\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OneHotEncoder 객체 생성\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "# 학습 데이터에 맞추기\n",
    "onehot_encoder.fit([[0], [1], [2]])\n",
    "\n",
    "# 변환\n",
    "transformed_data = onehot_encoder.transform([[1], [0], [2]]).toarray()\n",
    "\n",
    "print(transformed_data)\n",
    "# 출력: \n",
    "# [[0. 1. 0.]  # '보통출력'이면 1, 나머지는 0\n",
    "#  [1. 0. 0.]  # '고출력'이면 1, 나머지는 0\n",
    "#  [0. 0. 1.]]  # '저출력'이면 1, 나머지는 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing.LabelEncoder() 의 예제\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 예시 데이터\n",
    "categories = ['강아지', '고양이', '햄스터', '강아지', '고양이']\n",
    "\n",
    "# LabelEncoder 객체 생성, 범주형 데이터를 숫자로 변환하는데 사용\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "encoded_categories = label_encoder.fit_transform(categories)\n",
    "\n",
    "print(encoded_categories)\n",
    "# 강아지는 0, 고양이는 1, 햄스터는 2 => 강아지가 처음 나왔으므로 0번, 고양이-> 1번 , 햄스터가 마지막에 나와서 2번으로 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 2차원 행렬로 형태 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled),1) # len을 통해 onehot_labeled의 길이를 구하고\n",
    "                                                                # '1': 각 행에 하나의 열을 갖는 2차원 배열을 만들기위해 지정\n",
    "print(onehot_reshaped) # 세로로 길게 쌓은 2차원 배열이 됨\n",
    "print(type(onehot_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# 희소행렬 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더미 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      저출력   보통출력    고출력\n",
      "0   False   True  False\n",
      "1   False   True  False\n",
      "2   False   True  False\n",
      "3   False   True  False\n",
      "4   False   True  False\n",
      "5   False  False   True\n",
      "6   False  False   True\n",
      "7   False  False   True\n",
      "8   False  False   True\n",
      "9   False  False   True\n",
      "10  False  False   True\n",
      "11  False   True  False\n",
      "12  False   True  False\n",
      "13  False  False   True\n",
      "14   True  False  False\n"
     ]
    }
   ],
   "source": [
    "# .get_dummies() : 더미 함수, 범주형 데이터를 원-핫 인코딩하여 더미변수로 변환 , 각범주를 새로운 열로 확장하여 0 or 1의 이진값\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))\n",
    "\n",
    "\n",
    "# False 부문이 더미변수이고 True는 해당하는 범주에 값이 속한다는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_5. 데이터 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법 1. 해당 열의 최대값(절대값)으로 나누는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    392.000000\n",
      "mean     104.469388\n",
      "std       38.491160\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.500000\n",
      "75%      126.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "0    0.565217\n",
      "1    0.717391\n",
      "2    0.652174\n",
      "3    0.652174\n",
      "4    0.608696\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "count    392.000000\n",
      "mean       0.454215\n",
      "std        0.167353\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.406522\n",
      "75%        0.547826\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.horsepower.describe()) # describe 함수를 사용하면 count,mean,std,min,25%,50%,75%,max 값을 알려줌\n",
    "print()                         # 25%는 데이터의 크기순으로 나눴을때 1/4 지점에 위치한 값\n",
    "                                # 75%는 데이터의 크기순으로 나눴을때 3/4 지점에 위치한 값\n",
    "                                # std : 표준편차: 분포가 얼마나 퍼져있는지 나타내는 지표, 값이 작을수록 평균에 가깝다는뜻\n",
    "df.horsepower = df.horsepower / abs(df.horsepower.max())\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print()\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법 2. 최대값(max) - 최소값(min)으로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "count    392.000000\n",
      "mean     104.469388\n",
      "std       38.491160\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.500000\n",
      "75%      126.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "0    0.456522\n",
      "1    0.646739\n",
      "2    0.565217\n",
      "3    0.565217\n",
      "4    0.510870\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "count    392.000000\n",
      "mean       0.317768\n",
      "std        0.209191\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.258152\n",
      "75%        0.434783\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/choejong-gyu/Documents/05.데이터분석/data1/auto-mpg.csv',header=None)\n",
    "\n",
    "# 칼럼 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "# horsepower 열에 누락 데이터 '?' 우선 삭제\n",
    "import numpy as np\n",
    "\n",
    "df['horsepower'].replace('?',np.nan,inplace=True)\n",
    "df.dropna(subset=['horsepower'],axis=0,inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')     # .astype 으로 float형으로 변환\n",
    "\n",
    "print(df['horsepower'].dtypes) # horsepower의 타입\n",
    "print(df.horsepower.describe()) # 설명\n",
    "print()\n",
    "\n",
    "\n",
    "# 데이터 정규화 : (각데이터-최소값)/(최대값-최소값) 을 하면 0~1 사이의 값으로 정규화됨\n",
    "# 데이터 정규화를 하는 이유: 모델 성능 향상, 이상치 최소화, 모델의 안정성과 성능 향상\n",
    "min_x = df.horsepower - df.horsepower.min() \n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print()\n",
    "print(df.horsepower.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_6. 시계열 데이터(time series data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 자료형을 시계열 객체로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.to_datetime(변환할변수이름) :문자열 to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    20 non-null     object\n",
      " 1   Close   20 non-null     int64 \n",
      " 2   Start   20 non-null     int64 \n",
      " 3   High    20 non-null     int64 \n",
      " 4   Low     20 non-null     int64 \n",
      " 5   Volume  20 non-null     int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 주식 거래 관련 데이터\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock-data.csv')\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      20 non-null     object        \n",
      " 1   Close     20 non-null     int64         \n",
      " 2   Start     20 non-null     int64         \n",
      " 3   High      20 non-null     int64         \n",
      " 4   Low       20 non-null     int64         \n",
      " 5   Volume    20 non-null     int64         \n",
      " 6   new_Date  20 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# 문자열 데이터 -> 판다스 timestamp 변환, timestamp -> 시계열 데이터를 다루기 위해 사용\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.info())\n",
    "print()\n",
    "print(type(df['new_Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close  Start   High    Low  Volume\n",
      "new_Date                                      \n",
      "2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Close   20 non-null     int64\n",
      " 1   Start   20 non-null     int64\n",
      " 2   High    20 non-null     int64\n",
      " 3   Low     20 non-null     int64\n",
      " 4   Volume  20 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 960.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 변환했으니 필요한 데이터만 남기기\n",
    "df.set_index('new_Date',inplace=True)\n",
    "df.drop('Date',axis=1,inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to_period(freq ='자를 단위'): timestamp to period\n",
    "표기 단위 = { Y : 연 단위, M : 월 단위, D : 일 단위}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]')\n",
      "PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]')\n",
      "PeriodIndex(['2019', '2020', '2021'], dtype='period[A-DEC]')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = ['2019-01-01','2020-03-01','2021-06-01']\n",
    "ts_dates = pd.to_datetime(dates)            # 문자열 -> timestamp\n",
    "print(ts_dates)\n",
    "\n",
    "pr_day = ts_dates.to_period(freq='D')       # 일 단위까지 변환\n",
    "print(pr_day)\n",
    "\n",
    "pr_month = ts_dates.to_period(freq='M')     # 월 단위까지 자르기\n",
    "print(pr_month)\n",
    "\n",
    "pr_year = ts_dates.to_period(freq='Y')      # 연 단위까지 자르기\n",
    "print(pr_year)\n",
    "\n",
    "# pr_year = ts_dates.to_period()            # period 함수 안에 단위 안 넣어주면 에러 남\n",
    "# print(pr_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .date_range() : timestamp 배열\n",
    "속성들: freq=시간 간격, tz= 시간대, start=날짜 범위 시작점(선택 안 하면 월의 마지막 날이 디폴트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01 00:00:00+09:00', '2019-02-01 00:00:00+09:00',\n",
      "               '2019-03-01 00:00:00+09:00', '2019-04-01 00:00:00+09:00',\n",
      "               '2019-05-01 00:00:00+09:00', '2019-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n",
      "\n",
      "\n",
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-02-28 00:00:00+09:00',\n",
      "               '2019-03-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-05-31 00:00:00+09:00', '2019-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n",
      "\n",
      "\n",
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-07-31 00:00:00+09:00', '2019-10-31 00:00:00+09:00',\n",
      "               '2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 월 간격, 월의 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01',   # 날짜 범위 시작\n",
    "                      end=None,             # 날짜 범위 끝\n",
    "                      periods=6,            # 생성할 타임스탬프 개수\n",
    "                      freq='MS',            # 시간 간격(MS: month start)\n",
    "                      tz='Asia/Seoul')      # 시간대(timezone)\n",
    "\n",
    "print(ts_ms)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01',         # 날짜 범위 시작\n",
    "                      periods=6,            # 생성할 타임스탬프 개수\n",
    "                      freq='M',             # 시간 간격(MS: month start)\n",
    "                      tz='Asia/Seoul')      # 시간대(timezone)\n",
    "\n",
    "print(ts_me)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 분기(3개월) 간격, 월의 마지막 날 기준\n",
    "ts_3m = pd.date_range('2019-01-01',         # 날짜 범위 시작\n",
    "                      periods=6,            # 생성할 타임스탬프 개수\n",
    "                      freq='3M',            # 시간 간격(3M : 3 months)\n",
    "                      tz='Asia/Seoul')      # 시간대(timezone)\n",
    "\n",
    "print(ts_3m)\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .period_range() : period 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# period 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',      # 날짜 범위 시작\n",
    "                       end=None,                # 날짜 범위 끝\n",
    "                       periods=3,               # 생성할 period 개수\n",
    "                       freq='M')                # 기간 길이(H: 시간)\n",
    "print(pr_m)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['1998-10-25 00:00', '1998-10-25 01:00', '1998-10-25 02:00',\n",
      "             '1998-10-25 03:00', '1998-10-25 04:00', '1998-10-25 05:00',\n",
      "             '1998-10-25 06:00', '1998-10-25 07:00', '1998-10-25 08:00',\n",
      "             '1998-10-25 09:00', '1998-10-25 10:00', '1998-10-25 11:00',\n",
      "             '1998-10-25 12:00', '1998-10-25 13:00', '1998-10-25 14:00',\n",
      "             '1998-10-25 15:00', '1998-10-25 16:00', '1998-10-25 17:00',\n",
      "             '1998-10-25 18:00', '1998-10-25 19:00', '1998-10-25 20:00',\n",
      "             '1998-10-25 21:00', '1998-10-25 22:00', '1998-10-25 23:00'],\n",
      "            dtype='period[H]')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# period 배열 만들기 - 1시간 길이\n",
    "pr_h = pd.period_range(start='1998-10-25',      # 날짜 범위 시작\n",
    "                       end=None,                # 날짜 범위 끝\n",
    "                       periods=24,              # 생성할 period 개수\n",
    "                       freq='H')                # 기간 길이(H: 시간)\n",
    "print(pr_h)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['1998-10-25 10:00', '1998-10-25 12:00', '1998-10-25 14:00'], dtype='period[2H]')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# period 배열 만들기 - 2시간 길이\n",
    "pr_2h = pd.period_range(start='1998-10-25 10:25',      # 날짜 범위 시작\n",
    "                       end=None,                       # 날짜 범위 끝\n",
    "                       periods=3,                      # 생성할 period 개수\n",
    "                       freq='2H')                      # 기간 길이(H: 시간)\n",
    "print(pr_2h)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날짜 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './00.data/data_1/stock-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/choejong-gyu/Documents/05.데이터분석/04.데이터분석응용.ipynb 셀 96\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y201sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y201sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./00.data/data_1/stock-data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y201sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 문자열인 날짜 데이터를 판다스 timestamp로 변환\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y201sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mnew_Date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './00.data/data_1/stock-data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./00.data/data_1/stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 판다스 timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  \\\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7   \n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n",
      "\n",
      "   Day Date_yr   Date_m  \n",
      "0    2    2018  2018-07  \n",
      "1   29    2018  2018-06  \n",
      "2   28    2018  2018-06  \n",
      "3   27    2018  2018-06  \n",
      "4   26    2018  2018-06  \n",
      "\n",
      "\n",
      "period[A-DEC]\n",
      "period[M]\n"
     ]
    }
   ],
   "source": [
    "# timestamp를 period로 변환\n",
    "\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "print(df['Date_yr'].dtype)\n",
    "print(df['Date_m'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날짜 데이터별 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date  Close  Start   High    Low  Volume   new_Date  Year  \\\n",
      "Date_m                                                                     \n",
      "2018-07  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018   \n",
      "2018-06  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018   \n",
      "2018-06  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018   \n",
      "2018-06  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018   \n",
      "2018-06  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018   \n",
      "\n",
      "         Month  Day Date_yr  \n",
      "Date_m                       \n",
      "2018-07      7    2    2018  \n",
      "2018-06      6   29    2018  \n",
      "2018-06      6   28    2018  \n",
      "2018-06      6   27    2018  \n",
      "2018-06      6   26    2018  \n"
     ]
    }
   ],
   "source": [
    "# 날짜 추출 후 인덱스 설정\n",
    "\n",
    "df.set_index('Date_m',inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11월 21일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.데이터프레임의 다양한 사용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_1. 함수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:,['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 원소에 함수 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .apply() :시리즈 안의 개별 원소에 특정 함수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용자 함수 정의\n",
    "\n",
    "def add_10(n):\n",
    "    return n + 10\n",
    "\n",
    "def add_two_obj(a,b):\n",
    "    return a + b\n",
    "\n",
    "print(add_10(10))\n",
    "print(add_two_obj(10,10))\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "Name: age, dtype: float64 0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# [어떤 시리즈].apply(함수) : 어떤 시리즈에 속한 값(원소)들이 함수에 들어가게 됨, 결과는 또 다른 시리즈로 \n",
    "sr1 = df['age'].apply(add_10)\n",
    "\n",
    "print(df['age'].head(),sr1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n",
      "0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 시리즈 객체와 숫자에 적용 : 2개의 인수(시리즈 + 숫자)에 적용하기\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "sr2 = df['age'].apply(add_two_obj,b=10)\n",
    "print(sr2.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      32.0\n",
       "1      48.0\n",
       "2      36.0\n",
       "3      45.0\n",
       "4      45.0\n",
       "       ... \n",
       "886    37.0\n",
       "887    29.0\n",
       "888     NaN\n",
       "889    36.0\n",
       "890    42.0\n",
       "Name: age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .lambda() : 활용도가 매우 무궁무진한데 이렇게도 활용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# .lambda(): 시리즈 객체에 적용\n",
    "sr3 = df['age'].apply(lambda x : add_10(x))     # x가 시리즈 안의 원소를 뜻함\n",
    "print(sr3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .applymap() : 데이터프레임 안의 모든 시리즈가 가진 원소 각각에 특정 함수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:,['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "\n",
    "def add_10(n):\n",
    "    return n + 10\n",
    "\n",
    "def add_two_obj(a,b):\n",
    "    return a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  32.0  17.2500   20\n",
      "1  48.0  81.2833   20\n",
      "2  36.0  17.9250   20\n",
      "3  45.0  63.1000   20\n",
      "4  45.0  18.0500   20\n"
     ]
    }
   ],
   "source": [
    "df_map = df.applymap(add_10)  # 데이터프레임의 모든 원소에 add_10 적용\n",
    "print(df_map.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시리즈 객체에 함수 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .apply(함수,axis=0): 데이터 프레임의 각 열에 함수 매핑\n",
    "-> 함수에 column 시리즈 입력, column이 모인 시리즈 리턴 = 데이터프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:,['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "\n",
    "# 사용자 함수 정의\n",
    "def missing_value(series):      # null이 있는지 확인하는 함수\n",
    "    return series.isnull()      # insull에 들어갔다 나온 불린 시리즈를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   fare    ten\n",
      "0  False  False  False\n",
      "1  False  False  False\n",
      "2  False  False  False\n",
      "3  False  False  False\n",
      "4  False  False  False\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "result = df.apply(missing_value, axis=0)\n",
    "print(result.head())\n",
    "print()\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .apply(M:1 함수): 데이터프레임에 적용하고 결과물은 시리즈로 나옴\n",
    "-> 함수 자체가 여러 값을 받아 하나만 리턴하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      79.5800\n",
      "fare    512.3292\n",
      "ten       0.0000\n",
      "dtype: float64\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "def min_max(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "result = df.apply(min_max)\n",
    "print(result)\n",
    "print()\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .apply(람다함수 변수: 함수2(변수할당),axis=1): 데이터 프레임의 각 행에 함수 매핑 \n",
    "-> 함수에 row가 모인 시리즈 입력, row 결과값이 모인 시리즈 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n",
      "    age     fare  ten   add\n",
      "0  22.0   7.2500   10  32.0\n",
      "1  38.0  71.2833   10  48.0\n",
      "2  26.0   7.9250   10  36.0\n",
      "3  35.0  53.1000   10  45.0\n",
      "4  35.0   8.0500   10  45.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:,['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "\n",
    "# 사용자 함수 정의\n",
    "def add_two_obj(a,b):\n",
    "    return a + b\n",
    "\n",
    "df['add'] = df.apply(lambda x : add_two_obj(x['age'],x['ten']),axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .pipe() : 데이터프레임 객체에 함수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:,['age','fare']]\n",
    "\n",
    "\n",
    "# 사용자 함수 정의 \n",
    "def missing_value(x):               # 결과물 -> DataFrame\n",
    "    return x.isnull()\n",
    "\n",
    "def missing_count(x):               # 결과물 -> Series\n",
    "    return missing_value(x).sum()\n",
    "\n",
    "def total_number_missing(x):        # 결과물 -> value\n",
    "    return missing_count(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age   fare\n",
      "722  False  False\n",
      "742  False  False\n",
      "85   False  False\n",
      "830  False  False\n",
      "696  False  False\n",
      "782  False  False\n",
      "332  False  False\n",
      "726  False  False\n",
      "736  False  False\n",
      "741  False  False\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "result_df = df.pipe(missing_value)\n",
    "print(result_df.sample(10))\n",
    "print(type(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age     177\n",
      "fare      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "result_series = df.pipe(missing_count)\n",
    "print(result_series)\n",
    "print(type(result_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "result_value = df.pipe(total_number_missing)\n",
    "print(result_value)\n",
    "print(type(result_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/choejong-gyu/Documents/05.데이터분석/04.데이터분석응용.ipynb 셀 128\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y245sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 쟈근 실험\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y245sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_result \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mpipe(df\u001b[39m.\u001b[39mpipe(df\u001b[39m.\u001b[39mpipe(missing_value)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y245sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(test_result)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y245sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(test_result))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5926\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5924\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   5925\u001b[0m     \u001b[39mreturn\u001b[39;00m common\u001b[39m.\u001b[39mpipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m), func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5926\u001b[0m \u001b[39mreturn\u001b[39;00m common\u001b[39m.\u001b[39mpipe(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/common.py:518\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m func(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "# 쟈근 실험\n",
    "\n",
    "# test_result = df.pipe(df.pipe(df.pipe(missing_value)))\n",
    "# print(test_result)\n",
    "# print(type(test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_2. 열 재구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열 순서 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age\n",
      "0         0       3    male  22.0\n",
      "1         1       1  female  38.0\n",
      "2         1       3  female  26.0\n",
      "3         1       1  female  35.0\n",
      "4         0       3    male  35.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[0:4,'survived':'age']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'pclass', 'sex', 'age'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 리스트 만들기\n",
    "columns = list(df.columns.values)\n",
    "print(columns,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'pclass', 'sex', 'survived']\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 알파벳 순으로 정렬 - 내가 생각한 것 ^^\n",
    "columns.sort()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  pclass     sex  survived\n",
      "0  22.0       3    male         0\n",
      "1  38.0       1  female         1\n",
      "2  26.0       3  female         1\n",
      "3  35.0       1  female         1\n",
      "4  35.0       3    male         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sorted() : 열 이름 알파벳 순으로 정렬 - pd 내장함수\n",
    "columns_sorted = sorted(columns)\n",
    "df_sorted = df[columns_sorted]\n",
    "print(df_sorted,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex  pclass  survived\n",
      "0  22.0    male       3         0\n",
      "1  38.0  female       1         1\n",
      "2  26.0  female       3         1\n",
      "3  35.0  female       1         1\n",
      "4  35.0    male       3         0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reversed() : 열 이름 역순으로 정렬 - pd 내장함수\n",
    "columns_reversed = reversed(columns)\n",
    "df_reversed = df[columns_reversed]\n",
    "print(df_reversed,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass     sex   age  survived\n",
      "0       3    male  22.0         0\n",
      "1       1  female  38.0         1\n",
      "2       3  female  26.0         1\n",
      "3       1  female  35.0         1\n",
      "4       3    male  35.0         0\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 사용자 임의 지정\n",
    "columns_custom = ['pclass','sex','age','survived']\n",
    "df_custom = df[columns_custom]\n",
    "print(df_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 열 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         연월일   당일종가  전일종가     시가     고가     저가     거래량\n",
      "0 2018-07-02  10100   600  10850  10900  10000  137977\n",
      "1 2018-06-29  10700   300  10550  10900   9990  170253\n",
      "2 2018-06-28  10400   500  10900  10950  10150  155769\n",
      "3 2018-06-27  10900   100  10800  11050  10500  133548\n",
      "4 2018-06-26  10800   350  10900  11000  10700   63039 \n",
      "\n",
      "연월일     datetime64[ns]\n",
      "당일종가             int64\n",
      "전일종가             int64\n",
      "시가               int64\n",
      "고가               int64\n",
      "저가               int64\n",
      "거래량              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/주가데이터.xlsx')\n",
    "print(df.head(),'\\n')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [2018, 07, 02]\n",
      "1     [2018, 06, 29]\n",
      "2     [2018, 06, 28]\n",
      "3     [2018, 06, 27]\n",
      "4     [2018, 06, 26]\n",
      "5     [2018, 06, 25]\n",
      "6     [2018, 06, 22]\n",
      "7     [2018, 06, 21]\n",
      "8     [2018, 06, 20]\n",
      "9     [2018, 06, 19]\n",
      "10    [2018, 06, 18]\n",
      "11    [2018, 06, 15]\n",
      "12    [2018, 06, 14]\n",
      "13    [2018, 06, 12]\n",
      "14    [2018, 06, 11]\n",
      "15    [2018, 06, 08]\n",
      "16    [2018, 06, 07]\n",
      "17    [2018, 06, 05]\n",
      "18    [2018, 06, 04]\n",
      "19    [2018, 06, 01]\n",
      "Name: 연원일, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['연원일'] = df['연월일'].astype('str')\n",
    "dates = df['연원일'].str.split('-')\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# dates의 데이터 타입 확인하기\n",
    "print(type(dates))\n",
    "# print(type(dates[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2018\n",
      "1    2018\n",
      "2    2018\n",
      "3    2018\n",
      "4    2018\n",
      "Name: 연, dtype: object \n",
      "\n",
      "0    07\n",
      "1    06\n",
      "2    06\n",
      "3    06\n",
      "4    06\n",
      "Name: 월, dtype: object \n",
      "\n",
      "0    02\n",
      "1    29\n",
      "2    28\n",
      "3    27\n",
      "4    26\n",
      "Name: 일, dtype: object \n",
      "\n",
      "         연월일   당일종가  전일종가     시가     고가     저가     거래량     연   월   일\n",
      "0 2018-07-02  10100   600  10850  10900  10000  137977  2018  07  02\n",
      "1 2018-06-29  10700   300  10550  10900   9990  170253  2018  06  29\n",
      "2 2018-06-28  10400   500  10900  10950  10150  155769  2018  06  28\n",
      "3 2018-06-27  10900   100  10800  11050  10500  133548  2018  06  27\n",
      "4 2018-06-26  10800   350  10900  11000  10700   63039  2018  06  26\n"
     ]
    }
   ],
   "source": [
    "df['연'] = dates.str.get(0)\n",
    "df['월'] = dates.str.get(1)\n",
    "df['일'] = dates.str.get(2)\n",
    "print(df['연'].head(),'\\n')\n",
    "print(df['월'].head(),'\\n')\n",
    "print(df['일'].head(),'\\n')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_3. 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불린 인덱싱 ** mask연산(True or False 반환) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 미션 : mask 연산 이해하기\n",
    "1. 십대인 승객 선택하기\n",
    "2. 10세 미만이고 여성인 승객 선택하기\n",
    "3. 10세 미만 또는 60세 이상인 승객의 age, sex, alone 열만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### with 교수님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch      fare embarked   class  \\\n",
      "86          0       3    male  16.0      1      3   34.3750        S   Third   \n",
      "138         0       3    male  16.0      0      0    9.2167        S   Third   \n",
      "389         1       2  female  17.0      0      0   12.0000        C  Second   \n",
      "144         0       2    male  18.0      0      0   11.5000        S  Second   \n",
      "307         1       1  female  17.0      1      0  108.9000        C   First   \n",
      "887         1       1  female  19.0      0      0   30.0000        S   First   \n",
      "39          1       3  female  14.0      1      0   11.2417        C   Third   \n",
      "372         0       3    male  19.0      0      0    8.0500        S   Third   \n",
      "67          0       3    male  19.0      0      0    8.1583        S   Third   \n",
      "504         1       1  female  16.0      0      0   86.5000        S   First   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  teens  \n",
      "86     man        True  NaN  Southampton    no  False   16.0  \n",
      "138    man        True  NaN  Southampton    no   True   16.0  \n",
      "389  woman       False  NaN    Cherbourg   yes   True   17.0  \n",
      "144    man        True  NaN  Southampton    no   True   18.0  \n",
      "307  woman       False    C    Cherbourg   yes  False   17.0  \n",
      "887  woman       False    B  Southampton   yes   True   19.0  \n",
      "39   child       False  NaN    Cherbourg   yes  False   14.0  \n",
      "372    man        True  NaN  Southampton    no   True   19.0  \n",
      "67     man        True  NaN  Southampton    no   True   19.0  \n",
      "504  woman       False    B  Southampton   yes   True   16.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 십대인 승객 선택하기\n",
    "mask1 = (titanic.age >= 10) & (titanic.age < 20)\n",
    "df_teen = titanic.loc[mask1,:]\n",
    "print(df_teen.sample(10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex  age  sibsp  parch     fare embarked   class  \\\n",
      "852         0       3  female  9.0      1      1  15.2458        C   Third   \n",
      "535         1       2  female  7.0      0      2  26.2500        S  Second   \n",
      "541         0       3  female  9.0      4      2  31.2750        S   Third   \n",
      "530         1       2  female  2.0      1      1  26.0000        S  Second   \n",
      "10          1       3  female  4.0      1      1  16.7000        S   Third   \n",
      "43          1       2  female  3.0      1      2  41.5792        C  Second   \n",
      "813         0       3  female  6.0      4      2  31.2750        S   Third   \n",
      "184         1       3  female  4.0      0      2  22.0250        S   Third   \n",
      "237         1       2  female  8.0      0      2  26.2500        S  Second   \n",
      "642         0       3  female  2.0      3      2  27.9000        S   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  teens  \n",
      "852  child       False  NaN    Cherbourg    no  False    9.0  \n",
      "535  child       False  NaN  Southampton   yes  False    7.0  \n",
      "541  child       False  NaN  Southampton    no  False    9.0  \n",
      "530  child       False  NaN  Southampton   yes  False    2.0  \n",
      "10   child       False    G  Southampton   yes  False    4.0  \n",
      "43   child       False  NaN    Cherbourg   yes  False    3.0  \n",
      "813  child       False  NaN  Southampton    no  False    6.0  \n",
      "184  child       False  NaN  Southampton   yes  False    4.0  \n",
      "237  child       False  NaN  Southampton   yes  False    8.0  \n",
      "642  child       False  NaN  Southampton    no  False    2.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. 십세 미만이고 여성인 승객 선택하기\n",
    "mask2 = (titanic.age < 10) & (titanic.sex == 'female')\n",
    "df_girls = titanic.loc[mask2,:]\n",
    "print(df_girls.sample(10),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age     sex  alone\n",
      "480   9.0    male  False\n",
      "438  64.0    male  False\n",
      "10    4.0  female  False\n",
      "205   2.0  female  False\n",
      "366  60.0  female  False\n",
      "813   6.0  female  False\n",
      "869   4.0    male  False\n",
      "24    8.0  female  False\n",
      "750   4.0  female  False\n",
      "63    4.0    male  False\n"
     ]
    }
   ],
   "source": [
    "# 3. 십세 미만 또는 60세 이상인 승객의 age, sex, alone 열만 선택\n",
    "mask3 = (titanic.age < 10) | (titanic.age >= 60)\n",
    "df_children_grannies = titanic.loc[mask3,['age','sex','alone']] # 조건에 맞는 행과 해당 행들의 age,sex,alone열 선택\n",
    "print(df_children_grannies.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### isin() 메소드 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "68          1       3  female  17.0      4      2   7.9250        S  Third   \n",
      "278         0       3    male   7.0      4      1  29.1250        Q  Third   \n",
      "480         0       3    male   9.0      5      2  46.9000        S  Third   \n",
      "229         0       3  female   NaN      3      1  25.4667        S  Third   \n",
      "485         0       3  female   NaN      3      1  25.4667        S  Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "68   woman       False  NaN  Southampton   yes  False  \n",
      "278  child       False  NaN   Queenstown    no  False  \n",
      "480  child       False  NaN  Southampton    no  False  \n",
      "229  woman       False  NaN  Southampton    no  False  \n",
      "485  woman       False  NaN  Southampton    no  False  \n"
     ]
    }
   ],
   "source": [
    "# 함께 탑승한 형제 또는 배우자의 수가 3,4,5인 승객만 따로 추출 - 불린 인덱싱 버전\n",
    "mask_sib3 = titanic['sibsp'] == 3\n",
    "mask_sib4 = titanic['sibsp'] == 4\n",
    "mask_sib5 = titanic['sibsp'] == 5\n",
    "df_boolean = titanic[mask_sib3|mask_sib4|mask_sib5]\n",
    "print(df_boolean.sample(5))\n",
    "print('\\n')\n",
    "\n",
    "# 함께 탑승한 형제 또는 배우자의 수가 3,4,5인 승객만 따로 추출 - isin() 버전\n",
    "\n",
    "isin_filter = titanic['sibsp'].isin([3,4,5])\n",
    "df_isin = titanic[isin_filter]\n",
    "\n",
    "print(df_isin.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_4. 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  a0  b0  c0\n",
      "1  a1  b1  c1\n",
      "2  a2  b2  c2\n",
      "3  a3  b3  c3 \n",
      "\n",
      "    a   b   c   d\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'a':['a0','a1','a2','a3'],\n",
    "                    'b':['b0','b1','b2','b3'],\n",
    "                    'c':['c0','c1','c2','c3']},\n",
    "                   index=[0,1,2,3])\n",
    "\n",
    "df2 = pd.DataFrame({'a':['a2','a3','a4','a5'],\n",
    "                    'b':['b2','b3','b4','b5'],\n",
    "                    'c':['c2','c3','c4','c5'],\n",
    "                    'd':['d2','d3','d4','d5']}\n",
    "                   ,index=[2,3,4,5])\n",
    "\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .concat(): 데이터프레임 연결\n",
    "속성값들 \n",
    "-> axis = 0 or 1 / ignore_index = T or F / join = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 + 데이터프레임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .concat(axis=0) : 행 기준으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c    d\n",
      "0  a0  b0  c0  NaN\n",
      "1  a1  b1  c1  NaN\n",
      "2  a2  b2  c2  NaN\n",
      "3  a3  b3  c3  NaN\n",
      "2  a2  b2  c2   d2\n",
      "3  a3  b3  c3   d3\n",
      "4  a4  b4  c4   d4\n",
      "5  a5  b5  c5   d5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기본값 axis=0\n",
    "\n",
    "result1 = pd.concat([df1,df2])  \n",
    "print(result1,'\\n')\n",
    "# df1의 데이터 먼저 나오고 그 밑으로 df2 가 출력이 됨 df1에서 d가 없으면 NaN으로 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".concat(): ignore_index=True로 설정 -> 기존 데이터프레임의 지정인덱스 모두 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c    d\n",
      "0  a0  b0  c0  NaN\n",
      "1  a1  b1  c1  NaN\n",
      "2  a2  b2  c2  NaN\n",
      "3  a3  b3  c3  NaN\n",
      "4  a2  b2  c2   d2\n",
      "5  a3  b3  c3   d3\n",
      "6  a4  b4  c4   d4\n",
      "7  a5  b5  c5   d5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = pd.concat([df1,df2],ignore_index=True)  \n",
    "print(result1,'\\n')\n",
    "\n",
    "\n",
    "# df2의 기존에 있던 인덱스를 무시하고 새롭게 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".concat(,axis=1) : 칼럼 기준으로 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    a    b    c    d\n",
      "0   a0   b0   c0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   a3   b3   c3   d3\n",
      "4  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "5  NaN  NaN  NaN   a5   b5   c5   d5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = pd.concat([df1,df2],axis=1)  # 열 기준으로 연결한다는 뜻 \n",
    "print(result2,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "속성 join = 'inner': 교집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   a   b   c   d\n",
      "2  a2  b2  c2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  a3  b3  c3  d3\n"
     ]
    }
   ],
   "source": [
    "result_in = pd.concat([df1,df2],axis=1,join='inner') # 열기준으로 연결하고 inner: 교집합을 한다는 듯 \n",
    "                                                     # 행 2와 행3을 교집합\n",
    "print(result_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 + 시리즈 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시리즈 만들기\n",
    "\n",
    "sr1 = pd.Series(['e0','e1','e2','e3'],name='e')\n",
    "sr2 = pd.Series(['f0','f1','f2'],name='f',index=[3,4,5])\n",
    "sr3 = pd.Series(['g0','g1','g2','g3'],name='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  a0  b0  c0\n",
      "1  a1  b1  c1\n",
      "2  a2  b2  c2\n",
      "3  a3  b3  c3\n",
      "\n",
      "\n",
      "    a   b   c   e\n",
      "0  a0  b0  c0  e0\n",
      "1  a1  b1  c1  e1\n",
      "2  a2  b2  c2  e2\n",
      "3  a3  b3  c3  e3\n"
     ]
    }
   ],
   "source": [
    "# 좌우 열 방향으로 연결\n",
    "\n",
    "print(df1)\n",
    "print('\\n')\n",
    "result4 = pd.concat([df1,sr1],axis=1) # e -> sr1\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d    f\n",
      "2  a2  b2  c2  d2  NaN\n",
      "3  a3  b3  c3  d3   f0\n",
      "4  a4  b4  c4  d4   f1\n",
      "5  a5  b5  c5  d5   f2\n"
     ]
    }
   ],
   "source": [
    "# sort = True : 열의 인덱스 기준으로 정렬\n",
    "result5 = pd.concat([df2,sr2],axis=1,sort=True)\n",
    "print(result5)\n",
    "# a, b, c, d, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 시리즈를 행 기준, 열 기준으로 concat 했을 때 달라지는 데이터타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    e   g\n",
      "0  e0  g0\n",
      "1  e1  g1\n",
      "2  e2  g2\n",
      "3  e3  g3\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 칼럼 기준으로 연결 -> 데이터프레임이 됨\n",
    "result6 = pd.concat([sr1,sr3],axis=1)\n",
    "print(result6)\n",
    "print(type(result6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    e0\n",
      "1    e1\n",
      "2    e2\n",
      "3    e3\n",
      "0    g0\n",
      "1    g1\n",
      "2    g2\n",
      "3    g3\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 행 기준으로 연결 -> 그대로 시리즈임\n",
    "result7 = pd.concat([sr1,sr3],axis=0)\n",
    "print(result7)\n",
    "print(type(result7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .merge(): 데이터프레임 병합\n",
    "특정 기준으로 두 데이터프레임을 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_name          value   price\n",
      "0  128940       한미약품   59385.666667  421000\n",
      "1  130960     CJ E&M   58540.666667   98900\n",
      "2  138250      엔에스쇼핑   14558.666667   13200\n",
      "3  139480        이마트  239230.833333  254500\n",
      "4  142280     녹십자엠에스     468.833333   10200\n",
      "5  145990        삼양사   82750.000000   82000\n",
      "6  185750        종근당   40293.666667  100500\n",
      "7  192400      쿠쿠홀딩스  179204.666667  177500\n",
      "8  199800         툴젠   -2514.333333  115400\n",
      "9  204210     모두투어리츠    3093.333333    3475 \n",
      "\n",
      "       id       name           eps     bps        per       pbr\n",
      "0  130960     CJ E&M   6301.333333   54068  15.695091  1.829178\n",
      "1  136480         하림    274.166667    3551  11.489362  0.887074\n",
      "2  138040    메리츠금융지주   2122.333333   14894   6.313806  0.899691\n",
      "3  139480        이마트  18268.166667  295780  13.931338  0.860437\n",
      "4  145990        삼양사   5741.000000  108090  14.283226  0.758627\n",
      "5  161390      한국타이어   5648.500000   51341   7.453306  0.820007\n",
      "6  181710  NHN엔터테인먼트   2110.166667   78434  30.755864  0.827447\n",
      "7  185750        종근당   3990.333333   40684  25.185866  2.470259\n",
      "8  204210     모두투어리츠     85.166667    5335  40.802348  0.651359\n",
      "9  207940   삼성바이오로직스   4644.166667   60099  89.790059  6.938551 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock price.xlsx')\n",
    "df2 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock valuation.xlsx')\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_name          value   price    name           eps     bps  \\\n",
      "0  130960     CJ E&M   58540.666667   98900  CJ E&M   6301.333333   54068   \n",
      "1  139480        이마트  239230.833333  254500     이마트  18268.166667  295780   \n",
      "2  145990        삼양사   82750.000000   82000     삼양사   5741.000000  108090   \n",
      "3  185750        종근당   40293.666667  100500     종근당   3990.333333   40684   \n",
      "4  204210     모두투어리츠    3093.333333    3475  모두투어리츠     85.166667    5335   \n",
      "\n",
      "         per       pbr  \n",
      "0  15.695091  1.829178  \n",
      "1  13.931338  0.860437  \n",
      "2  14.283226  0.758627  \n",
      "3  25.185866  2.470259  \n",
      "4  40.802348  0.651359  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 교집합 : how=inner (디폴트 세팅)\n",
    "# on = None : 병합 기준(None, 공통 열) 설정\n",
    "# how=inner : 병합이 되는 방식(inner, 공통 인덱스) 설정\n",
    "merge_inner = pd.merge(df1,df2) # 기준이 없어서 두 데이터프레임 그냥 합쳐짐\n",
    "print(merge_inner)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id stock_name          value     price       name           eps  \\\n",
      "0   128940       한미약품   59385.666667  421000.0        NaN           NaN   \n",
      "1   130960     CJ E&M   58540.666667   98900.0     CJ E&M   6301.333333   \n",
      "2   138250      엔에스쇼핑   14558.666667   13200.0        NaN           NaN   \n",
      "3   139480        이마트  239230.833333  254500.0        이마트  18268.166667   \n",
      "4   142280     녹십자엠에스     468.833333   10200.0        NaN           NaN   \n",
      "5   145990        삼양사   82750.000000   82000.0        삼양사   5741.000000   \n",
      "6   185750        종근당   40293.666667  100500.0        종근당   3990.333333   \n",
      "7   192400      쿠쿠홀딩스  179204.666667  177500.0        NaN           NaN   \n",
      "8   199800         툴젠   -2514.333333  115400.0        NaN           NaN   \n",
      "9   204210     모두투어리츠    3093.333333    3475.0     모두투어리츠     85.166667   \n",
      "10  136480        NaN            NaN       NaN         하림    274.166667   \n",
      "11  138040        NaN            NaN       NaN    메리츠금융지주   2122.333333   \n",
      "12  161390        NaN            NaN       NaN      한국타이어   5648.500000   \n",
      "13  181710        NaN            NaN       NaN  NHN엔터테인먼트   2110.166667   \n",
      "14  207940        NaN            NaN       NaN   삼성바이오로직스   4644.166667   \n",
      "\n",
      "         bps        per       pbr  \n",
      "0        NaN        NaN       NaN  \n",
      "1    54068.0  15.695091  1.829178  \n",
      "2        NaN        NaN       NaN  \n",
      "3   295780.0  13.931338  0.860437  \n",
      "4        NaN        NaN       NaN  \n",
      "5   108090.0  14.283226  0.758627  \n",
      "6    40684.0  25.185866  2.470259  \n",
      "7        NaN        NaN       NaN  \n",
      "8        NaN        NaN       NaN  \n",
      "9     5335.0  40.802348  0.651359  \n",
      "10    3551.0  11.489362  0.887074  \n",
      "11   14894.0   6.313806  0.899691  \n",
      "12   51341.0   7.453306  0.820007  \n",
      "13   78434.0  30.755864  0.827447  \n",
      "14   60099.0  89.790059  6.938551  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# on = id : 병합 기준(id열) 설정\n",
    "# how = outer : 합집합, 없는 데이터는 NaN으로 들어감\n",
    "merge_outer = pd.merge(df1,df2,on='id',how='outer')\n",
    "print(merge_outer)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id_x stock_name          value   price      id_y    name           eps  \\\n",
      "0  128940       한미약품   59385.666667  421000       NaN     NaN           NaN   \n",
      "1  130960     CJ E&M   58540.666667   98900  130960.0  CJ E&M   6301.333333   \n",
      "2  138250      엔에스쇼핑   14558.666667   13200       NaN     NaN           NaN   \n",
      "3  139480        이마트  239230.833333  254500  139480.0     이마트  18268.166667   \n",
      "4  142280     녹십자엠에스     468.833333   10200       NaN     NaN           NaN   \n",
      "5  145990        삼양사   82750.000000   82000  145990.0     삼양사   5741.000000   \n",
      "6  185750        종근당   40293.666667  100500  185750.0     종근당   3990.333333   \n",
      "7  192400      쿠쿠홀딩스  179204.666667  177500       NaN     NaN           NaN   \n",
      "8  199800         툴젠   -2514.333333  115400       NaN     NaN           NaN   \n",
      "9  204210     모두투어리츠    3093.333333    3475  204210.0  모두투어리츠     85.166667   \n",
      "\n",
      "        bps        per       pbr  \n",
      "0       NaN        NaN       NaN  \n",
      "1   54068.0  15.695091  1.829178  \n",
      "2       NaN        NaN       NaN  \n",
      "3  295780.0  13.931338  0.860437  \n",
      "4       NaN        NaN       NaN  \n",
      "5  108090.0  14.283226  0.758627  \n",
      "6   40684.0  25.185866  2.470259  \n",
      "7       NaN        NaN       NaN  \n",
      "8       NaN        NaN       NaN  \n",
      "9    5335.0  40.802348  0.651359  \n"
     ]
    }
   ],
   "source": [
    "# how='left' : left join, 왼쪽 데이터프레임을 기준으로 병합\n",
    "#left_on / right_on : 각 데이터프레임에서 병합 기준이 될 칼럼 지정\n",
    "\n",
    "merge_left = pd.merge(df1,df2,how='left',left_on='stock_name',right_on='name')\n",
    "print(merge_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stock_name  value   name   price\n",
      "0       AAPL    200   AAPL  1500.0\n",
      "1      GOOGL    500  GOOGL  2000.0\n",
      "2       MSFT    150    NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'stock_name': ['AAPL', 'GOOGL', 'MSFT'],\n",
    "                    'value': [200, 500, 150]})\n",
    "df2 = pd.DataFrame({'name': ['AAPL', 'GOOGL', 'AMZN'],\n",
    "                    'price': [1500, 2000, 1800]})\n",
    "\n",
    "merge_left = pd.merge(df1, df2, how='left', left_on='stock_name', right_on='name')\n",
    "print(merge_left)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_x stock_name          value     price    id_y       name  \\\n",
      "0  130960.0     CJ E&M   58540.666667   98900.0  130960     CJ E&M   \n",
      "1       NaN        NaN            NaN       NaN  136480         하림   \n",
      "2       NaN        NaN            NaN       NaN  138040    메리츠금융지주   \n",
      "3  139480.0        이마트  239230.833333  254500.0  139480        이마트   \n",
      "4  145990.0        삼양사   82750.000000   82000.0  145990        삼양사   \n",
      "5       NaN        NaN            NaN       NaN  161390      한국타이어   \n",
      "6       NaN        NaN            NaN       NaN  181710  NHN엔터테인먼트   \n",
      "7  185750.0        종근당   40293.666667  100500.0  185750        종근당   \n",
      "8  204210.0     모두투어리츠    3093.333333    3475.0  204210     모두투어리츠   \n",
      "9       NaN        NaN            NaN       NaN  207940   삼성바이오로직스   \n",
      "\n",
      "            eps     bps        per       pbr  \n",
      "0   6301.333333   54068  15.695091  1.829178  \n",
      "1    274.166667    3551  11.489362  0.887074  \n",
      "2   2122.333333   14894   6.313806  0.899691  \n",
      "3  18268.166667  295780  13.931338  0.860437  \n",
      "4   5741.000000  108090  14.283226  0.758627  \n",
      "5   5648.500000   51341   7.453306  0.820007  \n",
      "6   2110.166667   78434  30.755864  0.827447  \n",
      "7   3990.333333   40684  25.185866  2.470259  \n",
      "8     85.166667    5335  40.802348  0.651359  \n",
      "9   4644.166667   60099  89.790059  6.938551  \n"
     ]
    }
   ],
   "source": [
    "# how='right' : right join, 오쪽 데이터프레임을 기준으로 병합\n",
    "#left_on / right_on : 각 데이터프레임에서 병합 기준이 될 칼럼 지정\n",
    "\n",
    "merge_right = pd.merge(df1,df2,how='right',left_on='stock_name',right_on='name')\n",
    "print(merge_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 미션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_name          value   price\n",
      "0  128940       한미약품   59385.666667  421000\n",
      "1  130960     CJ E&M   58540.666667   98900\n",
      "2  138250      엔에스쇼핑   14558.666667   13200\n",
      "3  139480        이마트  239230.833333  254500\n",
      "4  142280     녹십자엠에스     468.833333   10200\n",
      "5  145990        삼양사   82750.000000   82000\n",
      "6  185750        종근당   40293.666667  100500\n",
      "7  192400      쿠쿠홀딩스  179204.666667  177500\n",
      "8  199800         툴젠   -2514.333333  115400\n",
      "9  204210     모두투어리츠    3093.333333    3475 \n",
      "\n",
      "       id       name           eps     bps        per       pbr\n",
      "0  130960     CJ E&M   6301.333333   54068  15.695091  1.829178\n",
      "1  136480         하림    274.166667    3551  11.489362  0.887074\n",
      "2  138040    메리츠금융지주   2122.333333   14894   6.313806  0.899691\n",
      "3  139480        이마트  18268.166667  295780  13.931338  0.860437\n",
      "4  145990        삼양사   5741.000000  108090  14.283226  0.758627\n",
      "5  161390      한국타이어   5648.500000   51341   7.453306  0.820007\n",
      "6  181710  NHN엔터테인먼트   2110.166667   78434  30.755864  0.827447\n",
      "7  185750        종근당   3990.333333   40684  25.185866  2.470259\n",
      "8  204210     모두투어리츠     85.166667    5335  40.802348  0.651359\n",
      "9  207940   삼성바이오로직스   4644.166667   60099  89.790059  6.938551 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock price.xlsx')\n",
    "df2 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock valuation.xlsx')\n",
    "print(df1,'\\n')\n",
    "print(df2,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>value</th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "      <th>eps</th>\n",
       "      <th>bps</th>\n",
       "      <th>per</th>\n",
       "      <th>pbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130960</td>\n",
       "      <td>CJ E&amp;M</td>\n",
       "      <td>58540.666667</td>\n",
       "      <td>98900</td>\n",
       "      <td>CJ E&amp;M</td>\n",
       "      <td>6301.333333</td>\n",
       "      <td>54068</td>\n",
       "      <td>15.695091</td>\n",
       "      <td>1.829178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139480</td>\n",
       "      <td>이마트</td>\n",
       "      <td>239230.833333</td>\n",
       "      <td>254500</td>\n",
       "      <td>이마트</td>\n",
       "      <td>18268.166667</td>\n",
       "      <td>295780</td>\n",
       "      <td>13.931338</td>\n",
       "      <td>0.860437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145990</td>\n",
       "      <td>삼양사</td>\n",
       "      <td>82750.000000</td>\n",
       "      <td>82000</td>\n",
       "      <td>삼양사</td>\n",
       "      <td>5741.000000</td>\n",
       "      <td>108090</td>\n",
       "      <td>14.283226</td>\n",
       "      <td>0.758627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185750</td>\n",
       "      <td>종근당</td>\n",
       "      <td>40293.666667</td>\n",
       "      <td>100500</td>\n",
       "      <td>종근당</td>\n",
       "      <td>3990.333333</td>\n",
       "      <td>40684</td>\n",
       "      <td>25.185866</td>\n",
       "      <td>2.470259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204210</td>\n",
       "      <td>모두투어리츠</td>\n",
       "      <td>3093.333333</td>\n",
       "      <td>3475</td>\n",
       "      <td>모두투어리츠</td>\n",
       "      <td>85.166667</td>\n",
       "      <td>5335</td>\n",
       "      <td>40.802348</td>\n",
       "      <td>0.651359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id stock_name          value   price    name           eps     bps  \\\n",
       "0  130960     CJ E&M   58540.666667   98900  CJ E&M   6301.333333   54068   \n",
       "1  139480        이마트  239230.833333  254500     이마트  18268.166667  295780   \n",
       "2  145990        삼양사   82750.000000   82000     삼양사   5741.000000  108090   \n",
       "3  185750        종근당   40293.666667  100500     종근당   3990.333333   40684   \n",
       "4  204210     모두투어리츠    3093.333333    3475  모두투어리츠     85.166667    5335   \n",
       "\n",
       "         per       pbr  \n",
       "0  15.695091  1.829178  \n",
       "1  13.931338  0.860437  \n",
       "2  14.283226  0.758627  \n",
       "3  25.185866  2.470259  \n",
       "4  40.802348  0.651359  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나의 얼레벌레 -> df1에만 price라는 칼럼이 있기 때문에 masking 먼저 해야함 \n",
    "stock_inner = pd.merge(df1,df2,how='inner', on='id')\n",
    "stock_inner\n",
    "\n",
    "# mask = stock_inner['price'] >= 50000\n",
    "# stock_inner_mask = stock_inner[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_name          value   price\n",
      "0  128940       한미약품   59385.666667  421000\n",
      "1  130960     CJ E&M   58540.666667   98900\n",
      "3  139480        이마트  239230.833333  254500\n",
      "5  145990        삼양사   82750.000000   82000\n",
      "6  185750        종근당   40293.666667  100500\n"
     ]
    }
   ],
   "source": [
    "price = df1[df1['price']>= 50000]\n",
    "print(price.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_name          value   price    name           eps     bps  \\\n",
      "0  130960     CJ E&M   58540.666667   98900  CJ E&M   6301.333333   54068   \n",
      "1  139480        이마트  239230.833333  254500     이마트  18268.166667  295780   \n",
      "2  145990        삼양사   82750.000000   82000     삼양사   5741.000000  108090   \n",
      "3  185750        종근당   40293.666667  100500     종근당   3990.333333   40684   \n",
      "\n",
      "         per       pbr  \n",
      "0  15.695091  1.829178  \n",
      "1  13.931338  0.860437  \n",
      "2  14.283226  0.758627  \n",
      "3  25.185866  2.470259  \n"
     ]
    }
   ],
   "source": [
    "value = pd.merge(price,df2)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .join() : 데이터프레임 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock price.xlsx')\n",
    "df2 = pd.read_excel('/Users/choejong-gyu/Documents/05.데이터분석/data1/stock valuation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['id'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/choejong-gyu/Documents/05.데이터분석/04.데이터분석응용.ipynb 셀 186\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y361sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 데이터프레임 결합(join) , 두개의 데이터프레임을 인덱스를 기준으로 합치는 메서드\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y361sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df3 \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39mjoin(df2) \u001b[39m# 왼쪽인 df1의 인덱스를 기준으로 df2를 합침\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y361sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(df3)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/choejong-gyu/Documents/05.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D/04.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%9D%91%EC%9A%A9.ipynb#Y361sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9729\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[1;32m   9567\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9568\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m Iterable[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9574\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9575\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9576\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9577\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9578\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9727\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9728\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9729\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_join_compat(\n\u001b[1;32m   9730\u001b[0m         other,\n\u001b[1;32m   9731\u001b[0m         on\u001b[39m=\u001b[39mon,\n\u001b[1;32m   9732\u001b[0m         how\u001b[39m=\u001b[39mhow,\n\u001b[1;32m   9733\u001b[0m         lsuffix\u001b[39m=\u001b[39mlsuffix,\n\u001b[1;32m   9734\u001b[0m         rsuffix\u001b[39m=\u001b[39mrsuffix,\n\u001b[1;32m   9735\u001b[0m         sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m   9736\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m   9737\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9768\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9758\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   9759\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9760\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[1;32m   9761\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9766\u001b[0m             validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m   9767\u001b[0m         )\n\u001b[0;32m-> 9768\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9769\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   9770\u001b[0m         other,\n\u001b[1;32m   9771\u001b[0m         left_on\u001b[39m=\u001b[39mon,\n\u001b[1;32m   9772\u001b[0m         how\u001b[39m=\u001b[39mhow,\n\u001b[1;32m   9773\u001b[0m         left_index\u001b[39m=\u001b[39mon \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9774\u001b[0m         right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   9775\u001b[0m         suffixes\u001b[39m=\u001b[39m(lsuffix, rsuffix),\n\u001b[1;32m   9776\u001b[0m         sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m   9777\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m   9778\u001b[0m     )\n\u001b[1;32m   9779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9780\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    149\u001b[0m         left,\n\u001b[1;32m    150\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:811\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    809\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 811\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_and_concat(\n\u001b[1;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    813\u001b[0m )\n\u001b[1;32m    814\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:763\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    760\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[1;32m    761\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[0;32m--> 763\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    764\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright\u001b[39m.\u001b[39m_info_axis, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuffixes\n\u001b[1;32m    765\u001b[0m )\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[39mlen\u001b[39m(left)):\n\u001b[1;32m    768\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    772\u001b[0m         join_index,\n\u001b[1;32m    773\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    779\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2604\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2601\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[1;32m   2603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[0;32m-> 2604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2606\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix):\n\u001b[1;32m   2607\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['id'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# 데이터프레임 결합(join) , 두개의 데이터프레임을 인덱스를 기준으로 합치는 메서드\n",
    "\n",
    "df3 = df1.join(df2) # 왼쪽인 df1의 인덱스를 기준으로 df2를 합침\n",
    "print(df3)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임 결합(join) - 교집합\n",
    "df4 = df1.join(df2,how='inner')\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_5. 그룹 연산 : 데이터 안의 하위 그룹을 대상으로 연산 및 분석\n",
    "단계 : 분할(split) -> 적용(apply) -> 결합(combine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .groupby([  ]) : 분할 split_데이터를 특정 조건에 의해 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "승객 수 891\n",
      "    age  sex  class     fare  survived\n",
      "0  22.0  NaN    NaN   7.2500         0\n",
      "1  38.0  NaN    NaN  71.2833         1\n",
      "2  26.0  NaN    NaN   7.9250         1\n",
      "3  35.0  NaN    NaN  53.1000         1\n",
      "4  35.0  NaN    NaN   8.0500         0\n",
      "\n",
      "\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x15ff9bf90>\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "df = titanic.loc[:,['age','sex','class','fare','survived']]  # : 행 , ['age','sex','class','fare','survived'] : 열\n",
    "df = df.apply(pd.to_numeric, errors = 'coerce') # 숫자로 변환할수 없는 값이 있으면 NaN으로 처리\n",
    "                                                # 여기서 class가 문자열이기 때문에 NaN으로 되어있음\n",
    "\n",
    "print('승객 수',len(df))\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# class 기준으로 분할\n",
    "grouped = df.groupby(['class'])\n",
    "print(grouped)\n",
    "\n",
    "for key,group in grouped:\n",
    "    print(\"*key: \",key)\n",
    "    print(\"*number: \",len(group))  # 출력이 되지않은 이유는 NaN이기 때문에\n",
    "    print(group.head(5))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 적용 apply : 데이터를 집계, 변환, 필터링하는데 필요한 메소드 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [age, sex, fare, survived]\n",
      "Index: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average = grouped.mean(numeric_only=True) # 그룹 별 평균을 계산한 결과, numeric_only=True: 숫자형 열만 고려\n",
    "print(average)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex  class     fare  survived\n",
      "0  22.0    male  Third   7.2500         0\n",
      "2  26.0  female  Third   7.9250         1\n",
      "4  35.0    male  Third   8.0500         0\n",
      "5   NaN    male  Third   8.4583         0\n",
      "7   2.0    male  Third  21.0750         0\n"
     ]
    }
   ],
   "source": [
    "# # .get_group() : 개별 그룹 선택하기\n",
    "group3 = grouped.get_group('Third')\n",
    "print(group3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분할 -> 적용을 두 가지 열을 기준으로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** key :  ('First', 'female')\n",
      "** number:  94\n",
      "     age     sex  class      fare  survived\n",
      "1   38.0  female  First   71.2833         1\n",
      "3   35.0  female  First   53.1000         1\n",
      "11  58.0  female  First   26.5500         1\n",
      "31   NaN  female  First  146.5208         1\n",
      "52  49.0  female  First   76.7292         1\n",
      "\n",
      "\n",
      "** key :  ('First', 'male')\n",
      "** number:  122\n",
      "     age   sex  class      fare  survived\n",
      "6   54.0  male  First   51.8625         0\n",
      "23  28.0  male  First   35.5000         1\n",
      "27  19.0  male  First  263.0000         0\n",
      "30  40.0  male  First   27.7208         0\n",
      "34  28.0  male  First   82.1708         0\n",
      "\n",
      "\n",
      "** key :  ('Second', 'female')\n",
      "** number:  76\n",
      "     age     sex   class     fare  survived\n",
      "9   14.0  female  Second  30.0708         1\n",
      "15  55.0  female  Second  16.0000         1\n",
      "41  27.0  female  Second  21.0000         0\n",
      "43   3.0  female  Second  41.5792         1\n",
      "53  29.0  female  Second  26.0000         1\n",
      "\n",
      "\n",
      "** key :  ('Second', 'male')\n",
      "** number:  108\n",
      "     age   sex   class  fare  survived\n",
      "17   NaN  male  Second  13.0         1\n",
      "20  35.0  male  Second  26.0         0\n",
      "21  34.0  male  Second  13.0         1\n",
      "33  66.0  male  Second  10.5         0\n",
      "70  32.0  male  Second  10.5         0\n",
      "\n",
      "\n",
      "** key :  ('Third', 'female')\n",
      "** number:  144\n",
      "     age     sex  class     fare  survived\n",
      "2   26.0  female  Third   7.9250         1\n",
      "8   27.0  female  Third  11.1333         1\n",
      "10   4.0  female  Third  16.7000         1\n",
      "14  14.0  female  Third   7.8542         0\n",
      "18  31.0  female  Third  18.0000         0\n",
      "\n",
      "\n",
      "** key :  ('Third', 'male')\n",
      "** number:  347\n",
      "     age   sex  class     fare  survived\n",
      "0   22.0  male  Third   7.2500         0\n",
      "4   35.0  male  Third   8.0500         0\n",
      "5    NaN  male  Third   8.4583         0\n",
      "7    2.0  male  Third  21.0750         0\n",
      "12  20.0  male  Third   8.0500         0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "df = titanic.loc[:,['age','sex','class','fare','survived']]\n",
    "\n",
    "# print('승객 수',len(df))\n",
    "# print(df.head())\n",
    "# print('\\n')\n",
    "\n",
    "# class 열, sex 열을 기준으로 분할\n",
    "grouped_two = df.groupby(['class','sex'])\n",
    "\n",
    "\n",
    "for key, group in grouped_two:          # first,female -> first, male -> second,female ... -> third , male\n",
    "    print(\"** key : \",key)\n",
    "    print(\"** number: \",len(group))\n",
    "    print(group.head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     age        fare  survived\n",
      "class  sex                                    \n",
      "First  female  34.611765  106.125798  0.968085\n",
      "       male    41.281386   67.226127  0.368852\n",
      "Second female  28.722973   21.970121  0.921053\n",
      "       male    30.740707   19.741782  0.157407\n",
      "Third  female  21.750000   16.118810  0.500000\n",
      "       male    26.507589   12.661633  0.135447\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "average_two = grouped_two.mean() # 그룹두개의 평균\n",
    "print(average_two)\n",
    "print()\n",
    "print(type(average_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age     sex  class     fare  survived\n",
      "2   26.0  female  Third   7.9250         1\n",
      "8   27.0  female  Third  11.1333         1\n",
      "10   4.0  female  Third  16.7000         1\n",
      "14  14.0  female  Third   7.8542         0\n",
      "18  31.0  female  Third  18.0000         0\n"
     ]
    }
   ],
   "source": [
    "# .get_group() : 그룹별 개체 선택\n",
    "group3f = grouped_two.get_group(('Third','female'))\n",
    "print(group3f.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 열을 기준으로 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df = df.loc[:,['age','sex','class','fare','survived']]\n",
    "\n",
    "grouped = df.groupby(['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age       fare  survived\n",
      "class                                 \n",
      "First   14.802856  78.380373  0.484026\n",
      "Second  14.001077  13.417399  0.500623\n",
      "Third   12.495398  11.778142  0.428949\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .std(): 표준편자 집계\n",
    "\n",
    "std_all = grouped.std(numeric_only=True) # numeric_only = True -> 문자열이나 다른 데이터 타입은 표준편차에 제외\n",
    "print(std_all)\n",
    "print('\\n')\n",
    "print(type(std_all))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "First     78.380373\n",
      "Second    13.417399\n",
      "Third     11.778142\n",
      "Name: fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fare열의 표준편차 집계\n",
    "\n",
    "fare_std = grouped['fare'].std(numeric_only=True)\n",
    "print(fare_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "First     78.380373\n",
      "Second    13.417399\n",
      "Third     11.778142\n",
      "Name: fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fare열의 표준편차 집계 2\n",
    "\n",
    "fare_std2 = grouped.fare.std(numeric_only=True)\n",
    "print(fare_std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age   sex      fare  survived\n",
      "class                                  \n",
      "First   79.08  None  512.3292         1\n",
      "Second  69.33  None   73.5000         1\n",
      "Third   73.58  None   69.5500         1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그룹 객체에 agg() 메소드 적용\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "# from pandas.api.types import is_string_dtype\n",
    "\n",
    "def min_max(x):\n",
    "    if is_numeric_dtype(x): # 만약 숫자형 일경우 x.max() - x.min()\n",
    "        return x.max() - x.min()\n",
    "\n",
    "agg_minmax = grouped.agg(min_max) # agg 메서드는 그룹 객체에 다양한 집계함수를 적용할 수 있는 메서드\n",
    "print(agg_minmax.head())    # min_max 함수는 각열에 대해 수행\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fare                  age\n",
      "        min       max       mean\n",
      "class                           \n",
      "First   0.0  512.3292  38.233441\n",
      "Second  0.0   73.5000  29.877630\n",
      "Third   0.0   69.5500  25.140620\n"
     ]
    }
   ],
   "source": [
    "agg_sep = grouped.agg({'fare':['min','max'],'age':'mean'}) # fare에 대해서는 min,max값을 구하고 age는 mean평균값\n",
    "print(agg_sep.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .agg() :결합 combine_ 적용까지 완료된 처리 결과를 하나로 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_6. 멀티인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_7. 피벗"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
